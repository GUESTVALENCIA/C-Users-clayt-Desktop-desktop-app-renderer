#!/usr/bin/env node

/**
 * TEST OPENAI ADVANCED - Ajusta parÃ¡metros segÃºn el modelo
 *
 * Algunos modelos como GPT-5.2 y O3 usan max_completion_tokens en lugar de max_tokens
 */

require('dotenv').config();
const fs = require('fs');

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;

const results = {
  openai: {
    working: [],
    failed: [],
  }
};

console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
console.log('â•‘  ðŸ”„ PRUEBAS OPENAI AVANZADAS - AJUSTES DE PARÃMETROS          â•‘');
console.log('â•‘  Algunos modelos requieren parÃ¡metros especÃ­ficos              â•‘');
console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

if (!OPENAI_API_KEY) {
  console.error('âŒ ERROR: OPENAI_API_KEY no configurada');
  process.exit(1);
}

async function testModel(modelId, name, description, useCompletionTokens = false) {
  try {
    console.log(`â³ Probando: ${name} (${modelId})`);

    const body = {
      model: modelId,
      messages: [{
        role: 'user',
        content: 'Hola, Â¿estÃ¡s funcionando? Responde brevemente.'
      }],
      temperature: 0.3
    };

    // Algunos modelos usan max_completion_tokens
    if (useCompletionTokens) {
      body.max_completion_tokens = 100;
    } else {
      body.max_tokens = 100;
    }

    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${OPENAI_API_KEY}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(body)
    });

    const data = await response.json();

    if (response.ok && data.choices && data.choices[0]?.message?.content) {
      const content = data.choices[0].message.content;
      console.log(`   âœ… FUNCIONA - "${content.substring(0, 50)}..."\n`);

      results.openai.working.push({
        model: modelId,
        name: name,
        description: description,
        response: content.substring(0, 150),
        uses_completion_tokens: useCompletionTokens
      });
      return true;
    } else {
      const error = data.error?.message || 'Unknown error';
      console.log(`   âŒ ERROR: ${error}\n`);

      results.openai.failed.push({
        model: modelId,
        name: name,
        error: error
      });
      return false;
    }
  } catch (error) {
    console.log(`   âŒ EXCEPCIÃ“N: ${error.message}\n`);

    results.openai.failed.push({
      model: modelId,
      name: name,
      error: error.message
    });
    return false;
  }
}

async function runTests() {
  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

  // Probar modelos con max_tokens
  console.log('ðŸ“‹ MODELOS CON max_tokens (estÃ¡ndar):\n');
  await testModel('gpt-4o', 'GPT-4o', 'GPT-4 Optimized', false);

  // PequeÃ±a pausa
  await new Promise(r => setTimeout(r, 1000));

  // Probar modelos con max_completion_tokens
  console.log('ðŸ“‹ MODELOS CON max_completion_tokens (nuevo formato):\n');
  await testModel('gpt-5.2-2025-12-11', 'GPT-5.2 (2025-12-11)', 'Latest GPT-5.2', true);
  await new Promise(r => setTimeout(r, 1000));

  await testModel('gpt-5.2-pro', 'GPT-5.2 Pro', 'Professional variant', true);
  await new Promise(r => setTimeout(r, 1000));

  await testModel('o3-2025-04-16', 'O3 (2025-04-16)', 'Reasoning model O3', true);
  await new Promise(r => setTimeout(r, 1000));

  // Codex - probablemente no funcione en chat completions
  console.log('ðŸ“‹ MODELOS CODEX (Agents):\n');
  await testModel('gpt-5.1-codex-max', 'GPT-5.1 Codex Max', 'Codex agent', true);

  // Reporte
  console.log('\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
  console.log('â•‘  ðŸ“Š RESULTADO FINAL                                            â•‘');
  console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');

  console.log(`âœ… MODELOS FUNCIONANDO: ${results.openai.working.length}\n`);
  results.openai.working.forEach(m => {
    console.log(`   â€¢ ${m.name} (${m.model})`);
    console.log(`     ParÃ¡metro: ${m.uses_completion_tokens ? 'max_completion_tokens' : 'max_tokens'}`);
  });

  if (results.openai.failed.length > 0) {
    console.log(`\nâŒ MODELOS CON ERROR: ${results.openai.failed.length}\n`);
    results.openai.failed.forEach(m => {
      console.log(`   â€¢ ${m.name} (${m.model})`);
      console.log(`     Error: ${m.error}`);
    });
  }

  // Guardar reporte
  fs.writeFileSync('./test-openai-advanced-report.json', JSON.stringify(results, null, 2));
  console.log(`\nðŸ“„ Reporte guardado: test-openai-advanced-report.json\n`);

  console.log('â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n');
  console.log('ðŸ“‹ MODELOS PARA AGREGAR A CONFIGURACIÃ“N:\n');
  console.log('const PROVIDERS = {');
  console.log('  openai: {');
  console.log('    name: "ChatGPT",');
  console.log('    models: {');

  results.openai.working.forEach(m => {
    console.log(`      '${m.model}': { name: '${m.name}', context: 128000, speed: 'balanced', tested: true },`);
  });

  console.log('    }');
  console.log('  }');
  console.log('}\n');
}

runTests().catch(console.error);
